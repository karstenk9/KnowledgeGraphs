{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!pip install rdflib\n",
    "!pip install pykeen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from rdflib import ConjunctiveGraph\n",
    "\n",
    "graph_file = \"data/linkedmdb.trig\"\n",
    "g = ConjunctiveGraph()\n",
    "g.parse(graph_file, format=\"trig\")  # this takes around 15 minutes"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "len(g), type(g)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "named_graphs = list(g.contexts())\n",
    "named_graphs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data_graph = g.get_context(named_graphs[0].identifier)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data_triples = list(data_graph)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "relevant_triples = []\n",
    "\n",
    "properties = [\"actor\", \"director\", \"genre\", \"cinematographer\", \"producer\", \"editor\", \"writer\"]\n",
    "for s, p, o in data_triples:\n",
    "    s, p, o = str(s), str(p), str(o)\n",
    "    for prop in properties:\n",
    "        if p.endswith(\"/\" + prop):\n",
    "            relevant_triples.append((s,p,o))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "relevant_triples[:10]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# sparql_query = \"\"\"\n",
    "# SELECT DISTINCT ?film ?label\n",
    "# WHERE {\n",
    "#   ?film rdf:type <https://triplydb.com/Triply/linkedmdb/vocab/Film> .\n",
    "#   ?film rdfs:label ?label .\n",
    "# }\n",
    "# \"\"\"\n",
    "# results = g.query(sparql_query)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# len(results)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# for row in results:\n",
    "#     print(row[\"film\"], row[\"label\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# default_graph = g.get_context(named_graphs[1].identifier)\n",
    "# default_triples = list(default_graph)\n",
    "# default_triples"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# vocab_graph = g.get_context(named_graphs[2].identifier)\n",
    "# vocab_triples = list(vocab_graph)\n",
    "# vocab_triples"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# PyKeen needs tab seperated triple list txt file\n",
    "\n",
    "with open(\"triples.txt\", \"w\") as f:\n",
    "    for t in relevant_triples:\n",
    "        line = \"\\t\".join(t)\n",
    "        f.write(line + \"\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "using automatically assigned random_state=4063188918\n",
      "No random seed is specified. Setting to 1852656394.\n",
      "No cuda devices were available. The model runs on CPU\n"
     ]
    },
    {
     "data": {
      "text/plain": "Training epochs on cpu:   0%|          | 0/30 [00:00<?, ?epoch/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6d5700a00c674d79b2cf30d3709b5dad"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Training batches on cpu:   0%|          | 0/1619 [00:00<?, ?batch/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1f809201c0074ce5a7223d51d1454509"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Training batches on cpu:   0%|          | 0/1619 [00:00<?, ?batch/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3b2b84b2f8a4413eba897efcc14412bd"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Training batches on cpu:   0%|          | 0/1619 [00:00<?, ?batch/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fd1171dd82344b3ea1af6b805382f0b8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Training batches on cpu:   0%|          | 0/1619 [00:00<?, ?batch/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "316893f0ad6a4f78932b6c4b3a8d16d6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Training batches on cpu:   0%|          | 0/1619 [00:00<?, ?batch/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d970c834e6464cd0a282b52495278165"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Training batches on cpu:   0%|          | 0/1619 [00:00<?, ?batch/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e90527355200463e945d51766eff0537"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Training batches on cpu:   0%|          | 0/1619 [00:00<?, ?batch/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2ab96d785962498996a8890748dc218b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Training batches on cpu:   0%|          | 0/1619 [00:00<?, ?batch/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a6a6282c2723421cbf2342225f8047b4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Training batches on cpu:   0%|          | 0/1619 [00:00<?, ?batch/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f08ae54841044cf691f7f5a69eb6c9e1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Training batches on cpu:   0%|          | 0/1619 [00:00<?, ?batch/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ba632de70aec4138bd57ffcbe6fd3372"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pykeen.evaluation.evaluator:Currently automatic memory optimization only supports GPUs, but you're using a CPU. Therefore, the batch_size will be set to the default value.\n",
      "INFO:pykeen.evaluation.evaluator:No evaluation batch_size provided. Setting batch_size to '32'.\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 2914.94s seconds\n",
      "INFO:pykeen.stoppers.early_stopping:New best result at epoch 10: 0.03000463392029657. Saved model weights to C:\\Users\\KarstenK\\.data\\pykeen\\checkpoints\\best-model-weights-591056c4-6e31-453d-8162-307683446c14.pt\n",
      "INFO:pykeen.training.training_loop:=> Saved checkpoint after having finished epoch 10.\n"
     ]
    },
    {
     "data": {
      "text/plain": "Training batches on cpu:   0%|          | 0/1619 [00:00<?, ?batch/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fcc9601373bf497484ca5b3ca8c3edad"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Training batches on cpu:   0%|          | 0/1619 [00:00<?, ?batch/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "372ac99d92e64bb29194507747e78bce"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Training batches on cpu:   0%|          | 0/1619 [00:00<?, ?batch/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9bafae30066a4c4fad7994c71ecf833c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Training batches on cpu:   0%|          | 0/1619 [00:00<?, ?batch/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d20fcfe7e9654f3d8b9651514f651c1c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Training batches on cpu:   0%|          | 0/1619 [00:00<?, ?batch/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4b002e11c73a4e8bb8746bb24682534d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Training batches on cpu:   0%|          | 0/1619 [00:00<?, ?batch/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ca7827991bef40cf9d876a3ae246a218"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Training batches on cpu:   0%|          | 0/1619 [00:00<?, ?batch/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6881d3faeba14c168aaccaffc6df6aca"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Training batches on cpu:   0%|          | 0/1619 [00:00<?, ?batch/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bec4c041043542639ea14cd114d628bc"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Training batches on cpu:   0%|          | 0/1619 [00:00<?, ?batch/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "65db1a796d9f445dabf82475ace1233e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Training batches on cpu:   0%|          | 0/1619 [00:00<?, ?batch/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2956452d72664b8084d215d255668a07"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pykeen.evaluation.evaluator:Currently automatic memory optimization only supports GPUs, but you're using a CPU. Therefore, the batch_size will be set to the default value.\n",
      "INFO:pykeen.evaluation.evaluator:No evaluation batch_size provided. Setting batch_size to '32'.\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 3603.20s seconds\n",
      "INFO:pykeen.stoppers.early_stopping:New best result at epoch 20: 0.030699721964782205. Saved model weights to C:\\Users\\KarstenK\\.data\\pykeen\\checkpoints\\best-model-weights-591056c4-6e31-453d-8162-307683446c14.pt\n",
      "INFO:pykeen.training.training_loop:=> Saved checkpoint after having finished epoch 20.\n"
     ]
    },
    {
     "data": {
      "text/plain": "Training batches on cpu:   0%|          | 0/1619 [00:00<?, ?batch/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "abe1b226aa884ba4a6e26b2b789178e8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Training batches on cpu:   0%|          | 0/1619 [00:00<?, ?batch/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8b0873d39af94c2cae845811edc2a7a0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Training batches on cpu:   0%|          | 0/1619 [00:00<?, ?batch/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "987013b5d0bc435198aaf276de93bf5c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Training batches on cpu:   0%|          | 0/1619 [00:00<?, ?batch/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "af0b9e631c85435ab4c319ea6ba21a49"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Training batches on cpu:   0%|          | 0/1619 [00:00<?, ?batch/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8ab8b7595cc64bf18e4166894de530d9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Training batches on cpu:   0%|          | 0/1619 [00:00<?, ?batch/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "82517397298945f79826530c2538b9ed"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Training batches on cpu:   0%|          | 0/1619 [00:00<?, ?batch/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e948972aae4840588712566acfe264bc"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Training batches on cpu:   0%|          | 0/1619 [00:00<?, ?batch/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5f1ef9bfbae74fa1a1456dab600eb4bf"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Training batches on cpu:   0%|          | 0/1619 [00:00<?, ?batch/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "005614f888cd430b89e9c260232d084b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Training batches on cpu:   0%|          | 0/1619 [00:00<?, ?batch/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "57bdeb9b846046758e22fa975dd47596"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pykeen.evaluation.evaluator:Currently automatic memory optimization only supports GPUs, but you're using a CPU. Therefore, the batch_size will be set to the default value.\n",
      "INFO:pykeen.evaluation.evaluator:No evaluation batch_size provided. Setting batch_size to '32'.\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 3609.33s seconds\n",
      "INFO:pykeen.evaluation.evaluator:Currently automatic memory optimization only supports GPUs, but you're using a CPU. Therefore, the batch_size will be set to the default value.\n",
      "INFO:pykeen.evaluation.evaluator:No evaluation batch_size provided. Setting batch_size to '32'.\n"
     ]
    },
    {
     "data": {
      "text/plain": "Evaluating on cpu:   0%|          | 0.00/51.8k [00:00<?, ?triple/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b849615864d64b1097d07da77476e26b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pykeen.evaluation.evaluator:Evaluation took 3601.12s seconds\n",
      "INFO:pykeen.triples.triples_factory:Stored TriplesFactory(num_entities=201506, num_relations=7, create_inverse_triples=False, num_triples=414332, path=\"C:\\Repos\\KnowledgeGraphs\\triples.txt\") to file:///C:/Repos/KnowledgeGraphs/embeddings/training_triples\n",
      "INFO:pykeen.pipeline.api:Saved to directory: file:///C:/Repos/KnowledgeGraphs/embeddings\n"
     ]
    }
   ],
   "source": [
    "from pykeen.triples import TriplesFactory\n",
    "from pykeen.pipeline import pipeline\n",
    "\n",
    "tf = TriplesFactory.from_path(\"triples.txt\")\n",
    "training, testing, validation = tf.split([.8, .1, .1])\n",
    "\n",
    "result = pipeline(\n",
    "    training=training,\n",
    "    testing=testing,\n",
    "    validation=validation,\n",
    "    model='TransE',\n",
    "    stopper='early',\n",
    "    epochs=30,\n",
    ")\n",
    "result.save_to_directory(\"embeddings\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "from pykeen.triples import TriplesFactory\n",
    "import torch\n",
    "\n",
    "entity_to_id = TriplesFactory.from_path_binary(\"embeddings/training_triples\").entity_to_id\n",
    "model = torch.load(\"embeddings/trained_model.pkl\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "movie_id_to_embedding = dict()\n",
    "\n",
    "for entity_label, embedding_id in entity_to_id.items():\n",
    "    if \"/film/\" in entity_label:\n",
    "        movie_id = entity_label.split(\"/\")[-1]\n",
    "        embedding = model.entity_representations[0](torch.as_tensor(embedding_id))\n",
    "        movie_id_to_embedding[movie_id] = embedding.detach().numpy()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "import numpy as np\n",
    "\n",
    "def get_similar_movies(movie_id, number=12):\n",
    "\n",
    "    given_embed = movie_id_to_embedding[movie_id]\n",
    "\n",
    "    similarities = []\n",
    "    for other_embed in movie_id_to_embedding.values():\n",
    "        cos_sim = dot(given_embed, other_embed) / (norm(given_embed)*norm(other_embed))\n",
    "        similarities.append(cos_sim)\n",
    "\n",
    "    sim_sorted_indices_dsc = np.flip(np.argsort(similarities))[1:]\n",
    "    top_movie_ids = [list(movie_id_to_embedding.keys())[i] for i in sim_sorted_indices_dsc[:number]]\n",
    "    return top_movie_ids"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "['46642',\n '3640',\n '31536',\n '33782',\n '39906',\n '2218',\n '33482',\n '4568',\n '516',\n '2864',\n '8242',\n '48066']"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_similar_movies(\"72\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manual correction required for 'Rebecca' with ids: ['11611', '2141'].\n",
      "Manual correction required for 'Cool Hand Luke' with ids: ['27445', '8170'].\n",
      "Manual correction required for 'Ben-Hur' with ids: ['2243', '2245'].\n",
      "Manual correction required for 'Metropolis' with ids: ['2737', '14204', '63'].\n",
      "Manual correction required for 'Heat' with ids: ['20088', '4657', '53', '9200'].\n"
     ]
    }
   ],
   "source": [
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "import csv\n",
    "LMDB_PREFIX = \"<https://triplydb.com/Triply/linkedmdb/vocab/>\"\n",
    "SPARQL_ENDPOINT = \"https://api.triplydb.com/datasets/Triply/linkedmdb/services/linkedmdb/sparql\"\n",
    "\n",
    "def get_movie_id(movie_title):\n",
    "    query_str = f\"\"\"\n",
    "    PREFIX lmdb: {LMDB_PREFIX}\n",
    "\n",
    "    SELECT ?movie\n",
    "    WHERE {{\n",
    "      ?movie a lmdb:Film .\n",
    "      ?movie <http://purl.org/dc/terms/title> \"{movie_title}\" .\n",
    "    }}\n",
    "    \"\"\"\n",
    "\n",
    "    sparql = SPARQLWrapper(SPARQL_ENDPOINT)\n",
    "    sparql.setQuery(query_str)\n",
    "    sparql.setReturnFormat(JSON)\n",
    "    results = sparql.query().convert()\n",
    "\n",
    "    movie_ids = []\n",
    "    for result in results[\"results\"][\"bindings\"]:\n",
    "        movie_id = result[\"movie\"][\"value\"].split('/')[-1]\n",
    "        if (int(movie_id) >= 38000):\n",
    "            continue\n",
    "        movie_ids.append(movie_id)\n",
    "\n",
    "    return movie_ids\n",
    "\n",
    "movie_list = []\n",
    "with open('data/available_src_movies.csv') as file:\n",
    "    reader = csv.reader(file)\n",
    "    next(reader)\n",
    "    for row in reader:\n",
    "        movie_list.append(row[0])\n",
    "\n",
    "movie_id_dic = {}\n",
    "for movie in movie_list:\n",
    "    found_ids = get_movie_id(movie)\n",
    "    if (len(found_ids) == 1):\n",
    "        movie_id_dic[movie] = found_ids[0]\n",
    "    else:\n",
    "        print(f\"Manual correction required for '{movie}' with ids: {found_ids}.\")\n",
    "        movie_id_dic[movie] = found_ids\n",
    "movie_id_dic[\"Rebecca\"] = '2141'\n",
    "movie_id_dic[\"Cool Hand Luke\"] = '27445'\n",
    "movie_id_dic[\"Ben-Hur\"] = '2245'\n",
    "movie_id_dic[\"Metropolis\"] = '63'\n",
    "movie_id_dic[\"Heat\"] = '53'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "def get_title(movie_id):\n",
    "\n",
    "    q = f\"\"\"\n",
    "PREFIX lmdb: <https://triplydb.com/Triply/linkedmdb/vocab/>\n",
    "PREFIX dc: <http://purl.org/dc/terms/>\n",
    "\n",
    "SELECT ?title\n",
    "WHERE {{\n",
    "     ?movie dc:title ?title .\n",
    "     ?movie lmdb:filmid {movie_id} .\n",
    "}}\"\"\"\n",
    "\n",
    "    sparql = SPARQLWrapper(SPARQL_ENDPOINT)\n",
    "    sparql.setQuery(q)\n",
    "    sparql.setReturnFormat(JSON)\n",
    "    results = sparql.query().convert()\n",
    "    return results[\"results\"][\"bindings\"][0][\"title\"][\"value\"]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29381 High and Low\n",
      "1725\n",
      "Ray\n",
      "3173\n",
      "The Gathering\n",
      "15488\n",
      "Where's That Fire?\n",
      "7889\n",
      "Red Ensign\n",
      "27974\n",
      "Distant Lights\n",
      "9972\n",
      "Moonraker\n",
      "29\n",
      "Star Trek II: The Wrath of Khan\n",
      "47902\n",
      "The Lion Has Wings\n",
      "3379\n",
      "White Man's Burden\n",
      "82\n",
      "Tora! Tora! Tora!\n",
      "1400\n",
      "Wilson\n",
      "34379\n",
      "The Battle of Algiers\n",
      "\n",
      "27653 Das Boot\n",
      "65722\n",
      "The Ballad of Josie\n",
      "26721\n",
      "Blue in the Face\n",
      "2570\n",
      "Street Fighter II: The Animated Movie\n",
      "25430\n",
      "Addams Family Reunion\n",
      "61731\n",
      "The Barchester Chronicles\n",
      "41789\n",
      "Imaginary Heroes\n",
      "5107\n",
      "No Man's Land\n",
      "43981\n",
      "The Sunchaser\n",
      "13069\n",
      "Pride\n",
      "43233\n",
      "Night Has a Thousand Eyes\n",
      "7318\n",
      "Bleach: Memories of Nobody\n",
      "32896\n",
      "Robot Jox\n",
      "\n",
      "8 Dr. Strangelove or: How I Learned to Stop Worrying and Love the Bomb\n",
      "3179\n",
      "It's a Wonderful World\n",
      "1971\n",
      "Diner\n",
      "25331\n",
      "84 Charing Cross Road\n",
      "26249\n",
      "A Yank at Oxford\n",
      "13241\n",
      "Way for a Sailor\n",
      "1164\n",
      "After Hours\n",
      "135\n",
      "The Jazz Singer\n",
      "3372\n",
      "North Country\n",
      "2331\n",
      "My Blue Heaven\n",
      "43142\n",
      "Closet Land\n",
      "415\n",
      "Lilo & Stitch\n",
      "27721\n",
      "Dead Presidents\n",
      "\n",
      "1641 The Green Mile\n",
      "14013\n",
      "The Mummy 3\n",
      "8897\n",
      "Fast Food Nation\n",
      "11243\n",
      "Tugboat Annie\n",
      "3604\n",
      "Little Children\n",
      "39300\n",
      "Behind the Green Door\n",
      "41234\n",
      "Dil Chahta Hai\n",
      "38566\n",
      "Death Becomes Her\n",
      "40777\n",
      "The War Lord\n",
      "7223\n",
      "The Nutty Professor\n",
      "4754\n",
      "The Spiderwick Chronicles\n",
      "42484\n",
      "Robin and Marian\n",
      "35876\n",
      "The Moon-Spinners\n",
      "\n",
      "36433 The Silence of the Lambs\n",
      "27689\n",
      "Deadline at Dawn\n",
      "6370\n",
      "Eddie's Million Dollar Cook-Off\n",
      "8969\n",
      "Playing God\n",
      "9677\n",
      "Goodbye Again\n",
      "683\n",
      "Sinbad: Legend of the Seven Seas\n",
      "17692\n",
      "The Zodiac Killer\n",
      "11087\n",
      "The Internecine Project\n",
      "8541\n",
      "Header\n",
      "14182\n",
      "The Iron Mask\n",
      "31385\n",
      "Monsters, Inc.\n",
      "18521\n",
      "Goners\n",
      "254\n",
      "The Bishop's Wife\n",
      "\n",
      "29059 Goodfellas\n",
      "105\n",
      "Top Hat\n",
      "34522\n",
      "The Bone Collector\n",
      "36908\n",
      "The World of Henry Orient\n",
      "20485\n",
      "Take Me Out to the Ballgame\n",
      "25424\n",
      "Action of the Tiger\n",
      "19361\n",
      "Presence of Mind\n",
      "1072\n",
      "Demolition Man\n",
      "38566\n",
      "Death Becomes Her\n",
      "2411\n",
      "Body Double\n",
      "7848\n",
      "The Hound of the Baskervilles\n",
      "4232\n",
      "The Sniper\n",
      "4547\n",
      "The Namesake\n",
      "\n",
      "35175 The Good, the Bad and the Ugly\n",
      "35200\n",
      "The Great Escape\n",
      "12759\n",
      "Blood and Roses\n",
      "39190\n",
      "Pink Flamingos\n",
      "35656\n",
      "The Lives of Others\n",
      "58703\n",
      "You and Your Stupid Mate\n",
      "939\n",
      "Pandora's Box\n",
      "7208\n",
      "Duck! The Carbine High Massacre\n",
      "2815\n",
      "Kicking & Screaming\n",
      "27355\n",
      "Clownhouse\n",
      "3390\n",
      "Eve's Bayou\n",
      "3874\n",
      "Pride\n",
      "9409\n",
      "The Lost Patrol\n",
      "\n",
      "28677 Forrest Gump\n",
      "30664\n",
      "Le Grand Bleu\n",
      "38565\n",
      "Clueless\n",
      "33304\n",
      "Shakespeare in Love\n",
      "39102\n",
      "GoldenEye\n",
      "8333\n",
      "Roadie\n",
      "85\n",
      "The Good Earth\n",
      "784\n",
      "Wes Craven's New Nightmare\n",
      "406\n",
      "Julia\n",
      "14375\n",
      "Games of Love and Chance\n",
      "6800\n",
      "How Green Was My Valley\n",
      "6954\n",
      "Lupin the Third: Farewell to Nostradamus\n",
      "29\n",
      "Star Trek II: The Wrath of Khan\n",
      "\n",
      "35155 The Godfather Part II\n",
      "14602\n",
      "Reservation Road\n",
      "15597\n",
      "Wonder Boys\n",
      "1015\n",
      "Hearts of Darkness: A Filmmakers's Apocalypse\n",
      "1952\n",
      "The Secret Garden\n",
      "3513\n",
      "D.C. Cab\n",
      "265\n",
      "Halloween\n",
      "54349\n",
      "Trucker\n",
      "34979\n",
      "The Faculty\n",
      "25304\n",
      "40 Days and 40 Nights\n",
      "27696\n",
      "Deadly Friend\n",
      "5541\n",
      "Ocean's Thirteen\n",
      "9278\n",
      "School for Scoundrels\n",
      "\n",
      "122 Schindler's List\n",
      "68510\n",
      "Teenage Mutant Ninja Turtles\n",
      "25643\n",
      "Americathon\n",
      "14787\n",
      "Maangamizi: The Ancient One\n",
      "27415\n",
      "Condorman\n",
      "33215\n",
      "Seeing Other People\n",
      "10230\n",
      "Pennies from Heaven\n",
      "3173\n",
      "The Gathering\n",
      "8215\n",
      "Burglar\n",
      "3834\n",
      "Midnight\n",
      "47569\n",
      "Hood of Horror\n",
      "4282\n",
      "Over the Hedge\n",
      "8300\n",
      "Cop\n",
      "\n",
      "35153 The Godfather\n",
      "17811\n",
      "Aachi & Ssipak\n",
      "44694\n",
      "Dhadkan\n",
      "1552\n",
      "Peyton Place\n",
      "12672\n",
      "Let's Do It Again\n",
      "47307\n",
      "Zavallilar\n",
      "95549\n",
      "Red Riding: 1983\n",
      "7677\n",
      "The Clock\n",
      "27551\n",
      "Curse of the Pink Panther\n",
      "2822\n",
      "The Honeymooners\n",
      "801\n",
      "Ladies and Gentlemen, The Fabulous Stains\n",
      "32529\n",
      "Puppet Master III\n",
      "38962\n",
      "Caddyshack\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('data/embedding_movies_recs.csv', 'w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file, delimiter=',')\n",
    "    for movie_title, movie_id in list(movie_id_dic.items()):\n",
    "        print(movie_id, movie_title)\n",
    "        recs = get_similar_movies(movie_id)\n",
    "        line = [movie_title]\n",
    "        for rec_id in recs:\n",
    "            print(rec_id)\n",
    "            title = get_title(rec_id)\n",
    "            print(title)\n",
    "            line.append(title)\n",
    "        writer.writerow(line)\n",
    "        print()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}